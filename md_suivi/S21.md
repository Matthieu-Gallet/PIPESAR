# Summary par semaine: 
## Activités principales :

- Installation des environnements de développement et des bibliothèques Python sur l'environnement Miniconda.
- Création du dépôt GitHub pour le suivi et création du pipeline.
- Création du pipeline et implémentation des nouvelles technologies.
- Implémentation des méthodes kfold et répartition des données pour l'entraînement.
- Ajout des méthodes pour la création de générateur de folds pour l'entraînement et création de docs du pipeline.


# Summary par jour: 

## Rapport quotidien - 21/05/2024

### Résumé
Aujourd'hui, installation des environnements de développement et des bibliothèques Python.

### Tâches accomplies
- Tâche 1 : Installation des bibliothèques Python sur l'environnement Miniconda.
- Tâche 2 : Création du dépôt GitHub pour le suivi et création du pipeline.

### En cours
- Tâche 1 : Lecture et compréhension du code.

### Problèmes et défis
- Problème 1 : L'installation des paquets par Matthieu a été faite sur l'ordinateur du LISTIC et non sur le compte personnel, donc il faut refaire toutes les installations sur le compte personnel : `cortesmc`.

### Notes
- Aucune note supplémentaire pour le moment.

### Questions
- Qu'est-ce que l'estimation de Nagler ? Pourquoi la faire au début du pipeline ?
- Est-ce que les données de sortie de `dataset_load.py` sont du même type que les données de sortie de `dataset_management.py` ?
- Est-ce que je peux utiliser la fonction `load_data` ou `request_data` de `dataset_load.py` et faire la séparation du jeu de données en jeu d'entraînement et jeu de test pour obtenir le même type de données que les sorties des fonctions `load_train` et `load_test` de `dataset_management.py` ?

---

## Rapport quotidien - 22/05/2024

### Résumé
Création du pipeline et implémentation des nouvelles technologies.

### En cours
- Tâche 1 : Implémentation de `load_dataset.py`.

### Problèmes et défis
- Double colonne "aquisition" qui empêche la recherche avec des requêtes, solution : changement de `aquisition` --> `aquisition2`. Solution à vérifier.
- Je ne trouve pas les labels dans les informations sortantes dans `dataset_load.py`. Est-ce qu'on en a besoin pour l'apprentissage non supervisé ?

### Questions
- Qu'est-ce que la colonne "tel" ?

### Notes
- Ajout de la fonction `set_label_CROCUS()` dans `dataset_load.py`, qui utilise la condition --> (['tmin'] > 0) & (['hsnow'] > 0.4).

---

## Rapport quotidien - 23/05/2024

### Résumé
Implémentation des méthodes kfold et répartition de données pour l'entraînement.

### Tâches accomplies
- Tâche 1 : Implémentation de la méthode kfold.

### En cours
- Tâche 1 : Implémentation de la méthode fold by massive.
- Tâche 2 : Implémentation de classe pour la gestion des labels, selon la fonction choisie.

### Problèmes et défis
- Problème 1 : Distribution de données entre les ensembles d'entraînement et de test.
- Problème 2 : Multiples options pour la distribution des données et gestion des "imbalance data".

### Notes
- Classe label créée mais non développée.

---

## Rapport quotidien - 24/05/2024

### Résumé
Ajout des méthodes pour la création de générateur de folds pour l'entraînement et création de docs du pipeline.

### Tâches accomplies
- Tâche 1 : Création de docs pour le pipeline avec Sphinx.
- Tâche 2 : Création et implémentations des 3 méthodes fold.
- Tâche 3 : Test de toutes les fonctions fold.

### En cours
- Tâche 1 : Création de la fonction de création de labels, manque la condition.

### Problèmes et défis
- Problème 1 : Distribution des données dans le dictionnaire "y".

### Notes
- Les modèles .yml commencent à se surcharger, il faut nettoyer un peu les variables.

