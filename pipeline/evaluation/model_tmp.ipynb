{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from estimators.statistical_descriptor import Nagler_WS\n",
    "# from plot.figure_roc import ROC_plot\n",
    "from utils.dataset_management import parse_pipeline\n",
    "from utils.dataset_load import shuffle_data, DatasetLoader\n",
    "from utils.fold_management import FoldManagement\n",
    "from utils.label_management import LabelManagement\n",
    "from utils.figures import plot_boxplots, plot_roc_curves\n",
    "from utils.files_management import (\n",
    "    load_yaml,\n",
    "    dump_pkl,\n",
    "    init_logger,\n",
    "    report_prediction,\n",
    "    report_metric_from_log,\n",
    "    set_folder,\n",
    "    logger_dataset,\n",
    "    logger_fold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_path = \"../parameter/config_pipeline.yml\"\n",
    "pipeline_params = load_yaml(param_path)\n",
    "\n",
    "try:\n",
    "    data_path = \"../data/dataset/dataset_AD_08200821_14Mas3Top3Phy_W15_corrected_V2.h5\"\n",
    "    out_dir = pipeline_params[\"out_dir\"]\n",
    "    fold_method = pipeline_params[\"fold_method\"]\n",
    "    seed = pipeline_params[\"seed\"]\n",
    "    labeling_method = pipeline_params[\"labeling_method\"]\n",
    "    resampling_method = pipeline_params[\"resampling_method\"]\n",
    "    balance_data = pipeline_params[\"balance_data\"]\n",
    "    # orbit = pipeline_params[\"orbit\"]\n",
    "    request = pipeline_params[\"request\"]\n",
    "    shuffle_data = pipeline_params[\"shuffle_data\"]\n",
    "    channel_transformation = pipeline_params[\"channel_transformation\"]\n",
    "    BANDS_MAX = pipeline_params[\"BANDS_MAX\"]\n",
    "\n",
    "except KeyError as e:\n",
    "    print(\"KeyError: %s undefined\" % e)\n",
    "\n",
    "out_dir = set_folder(out_dir, pipeline_params)\n",
    "log_dataset, _ = init_logger(out_dir, \"dataset_info\")\n",
    "log_results, _ = init_logger(out_dir + \"results\", \"results\")\n",
    "\n",
    "dataset_loader = DatasetLoader(\n",
    "    data_path,\n",
    "    shuffle=shuffle_data,\n",
    "    descrp=[\n",
    "        \"date\",\n",
    "        \"massif\",\n",
    "        \"acquisition\",\n",
    "        \"elevation\",\n",
    "        \"slope\",\n",
    "        \"orientation\",\n",
    "        \"tmin\",\n",
    "        \"hsnow\",\n",
    "        \"tel\"\n",
    "    ],\n",
    "    print_info=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request: (date.dt.month == 3 and date.dt.day == 1) and ((elevation > 1000) and (elevation < 1500)) with 2577 samples\n",
      "(2577, 15, 15, 9)\n"
     ]
    }
   ],
   "source": [
    "x, y = dataset_loader.request_data(request)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_manager = LabelManagement(method=labeling_method)\n",
    "\n",
    "targets = labels_manager.transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "massives_count = {}\n",
    "for index, name in enumerate(y['metadata'][:, 1]):\n",
    "            if name not in massives_count:\n",
    "                massives_count[name] = {'count': 0, 'indices': []}\n",
    "            massives_count[name]['count'] += 1\n",
    "            massives_count[name]['indices'].append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def combination_method(dict_massives, train_size=0.8, proximity_value=1, shuffle=False, seed=None):\n",
    "    \"\"\"\n",
    "    Generate prioritized combinations of massives based on a given dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - dict_massives : dict\n",
    "        A dictionary where keys are massives and values are dictionaries containing 'count' and 'indices' keys.\n",
    "        Example: {\n",
    "            'massif1': {'count': 10, 'indices': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]},\n",
    "            'massif2': {'count': 5, 'indices': [10, 11, 12, 13, 14]},\n",
    "            ...\n",
    "        }\n",
    "    - train_size : float, optional (default=0.8)\n",
    "        The proportion of the dataset to include in the train split.\n",
    "    - proximity_value : int, optional (default=1)\n",
    "        A value to control the proximity to the desired train size.\n",
    "    - shuffle : bool, optional (default=False)\n",
    "        Whether to shuffle the selection of combinations.\n",
    "    - seed : int, optional (default=None)\n",
    "        Seed for random number generator (used if shuffle is True).\n",
    "\n",
    "    Returns:\n",
    "    - list of tuples\n",
    "        A list containing train and test indices for each prioritized combination of massives.\n",
    "    \"\"\"\n",
    "    if shuffle:\n",
    "        random.seed(seed)\n",
    "\n",
    "    total_count = sum(value['count'] for value in dict_massives.values())\n",
    "    massives = list(dict_massives.keys())\n",
    "    sorted(massives)\n",
    "    \n",
    "    all_combinations = []\n",
    "    for r in range(1, len(massives)):\n",
    "        combinations_object = itertools.combinations(massives, r)\n",
    "        combinations_list = list(combinations_object)\n",
    "        all_combinations.extend(combinations_list)\n",
    "\n",
    "    valid_combinations = []\n",
    "    for combo in all_combinations:\n",
    "        combo_count = sum(dict_massives[massif]['count'] for massif in combo)\n",
    "        percentage = (combo_count / total_count) * 100\n",
    "        if (train_size * 100) - proximity_value <= percentage <= (train_size * 100) + proximity_value:\n",
    "            valid_combinations.append(combo)\n",
    "\n",
    "    valid_combinations.sort(key=lambda combo: len(combo))\n",
    "\n",
    "    if shuffle:\n",
    "        random.shuffle(valid_combinations)\n",
    "\n",
    "    uncovered_train_massives = set(massives)\n",
    "    uncovered_test_massives = set(massives)\n",
    "    selected_combinations = []\n",
    "\n",
    "    for combo in valid_combinations:\n",
    "        if not uncovered_train_massives and not uncovered_test_massives:\n",
    "            break\n",
    "\n",
    "        train_massifs_in_combo = set(combo)\n",
    "        test_massifs_in_combo = set(massives) - train_massifs_in_combo\n",
    "\n",
    "        if uncovered_train_massives & train_massifs_in_combo or uncovered_test_massives & test_massifs_in_combo:\n",
    "            selected_combinations.append(combo)\n",
    "            uncovered_train_massives -= train_massifs_in_combo\n",
    "            uncovered_test_massives -= test_massifs_in_combo\n",
    "\n",
    "    result = []\n",
    "    for combo in selected_combinations:\n",
    "        train_indices = []\n",
    "        test_indices = []\n",
    "        for massif in massives:\n",
    "            if massif in combo:\n",
    "                train_indices.extend(dict_massives[massif]['indices'])\n",
    "            else:\n",
    "                test_indices.extend(dict_massives[massif]['indices'])\n",
    "\n",
    "        result.append((train_indices, test_indices))\n",
    "\n",
    "    return result\n",
    "\n",
    "def balance_classes(results, targets, method='oversample', seed=42):\n",
    "    \"\"\"\n",
    "    Balance the classes within each fold using the specified method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results : list of tuples\n",
    "        A list containing train and test indices for each fold.\n",
    "    targets : numpy.ndarray\n",
    "        Target labels.\n",
    "    method : str, optional (default='oversample')\n",
    "        The resampling method to use ('oversample', 'undersample', 'smote').\n",
    "    seed : int, optional (default=42)\n",
    "        Seed for random number generator.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of tuples\n",
    "        A list containing balanced train and test indices for each fold.\n",
    "    \"\"\"\n",
    "    balanced_results = []\n",
    "\n",
    "    for train_indices, test_indices in results:\n",
    "        train_targets = targets[train_indices]\n",
    "        \n",
    "        if method == 'oversample':\n",
    "            sampler = RandomOverSampler(random_state=seed)\n",
    "            balanced_train_indices, _ = sampler.fit_resample(np.array(train_indices).reshape(-1, 1), train_targets)\n",
    "            balanced_train_indices = balanced_train_indices.flatten()\n",
    "        \n",
    "        elif method == 'undersample':\n",
    "            sampler = RandomUnderSampler(random_state=seed)\n",
    "            balanced_train_indices, _ = sampler.fit_resample(np.array(train_indices).reshape(-1, 1), train_targets)\n",
    "            balanced_train_indices = balanced_train_indices.flatten()\n",
    "        \n",
    "        elif method == 'smote':\n",
    "            sampler = SMOTE(random_state=seed)\n",
    "            balanced_train_indices, _ = sampler.fit_resample(np.array(train_indices).reshape(-1, 1), train_targets)\n",
    "            balanced_train_indices = balanced_train_indices.flatten()\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown resampling method: {method}\")\n",
    "\n",
    "        balanced_results.append((balanced_train_indices.tolist(), test_indices))\n",
    "\n",
    "    return balanced_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Fold: 0 ------------------\n",
      "    - Distribution class train: 0: 902 (50.00%), 1: 902 (50.00%)\n",
      "    - Distribution class test: 0: 328 (63.08%), 1: 192 (36.92%)\n",
      "    - Train size: 77.62%\n",
      "    - Massif in train: ['ARAVIS' 'BAUGES' 'BELLEDONNE' 'CHARTEUSE' 'GRANDES-ROUSSES' 'HTE-MAURIE'\n",
      " 'HTE-TARENT' 'MAURIENNE' 'MONT-BLANC']\n",
      "    - Massif in test: ['BEAUFORTAIN' 'VANOISE' 'VERCORS']\n",
      "------------------ Fold: 1 ------------------\n",
      "    - Distribution class train: 0: 757 (50.00%), 1: 757 (50.00%)\n",
      "    - Distribution class test: 0: 199 (37.13%), 1: 337 (62.87%)\n",
      "    - Train size: 73.85%\n",
      "    - Massif in train: ['ARAVIS' 'BAUGES' 'BEAUFORTAIN' 'CHARTEUSE' 'HTE-MAURIE' 'HTE-TARENT'\n",
      " 'MAURIENNE' 'VANOISE']\n",
      "    - Massif in test: ['BELLEDONNE' 'GRANDES-ROUSSES' 'MONT-BLANC' 'VERCORS']\n",
      "------------------ Fold: 2 ------------------\n",
      "    - Distribution class train: 0: 883 (50.00%), 1: 883 (50.00%)\n",
      "    - Distribution class test: 0: 295 (58.30%), 1: 211 (41.70%)\n",
      "    - Train size: 77.73%\n",
      "    - Massif in train: ['ARAVIS' 'BAUGES' 'BEAUFORTAIN' 'BELLEDONNE' 'HTE-MAURIE' 'HTE-TARENT'\n",
      " 'MAURIENNE' 'MONT-BLANC' 'VANOISE']\n",
      "    - Massif in test: ['CHARTEUSE' 'GRANDES-ROUSSES' 'VERCORS']\n",
      "------------------ Fold: 3 ------------------\n",
      "    - Distribution class train: 0: 892 (50.00%), 1: 892 (50.00%)\n",
      "    - Distribution class test: 0: 316 (61.00%), 1: 202 (39.00%)\n",
      "    - Train size: 77.50%\n",
      "    - Massif in train: ['ARAVIS' 'BAUGES' 'BEAUFORTAIN' 'BELLEDONNE' 'HTE-MAURIE' 'MAURIENNE'\n",
      " 'MONT-BLANC' 'VANOISE' 'VERCORS']\n",
      "    - Massif in test: ['CHARTEUSE' 'GRANDES-ROUSSES' 'HTE-TARENT']\n",
      "------------------ Fold: 4 ------------------\n",
      "    - Distribution class train: 0: 921 (50.00%), 1: 921 (50.00%)\n",
      "    - Distribution class test: 0: 366 (67.90%), 1: 173 (32.10%)\n",
      "    - Train size: 77.36%\n",
      "    - Massif in train: ['ARAVIS' 'BAUGES' 'BELLEDONNE' 'CHARTEUSE' 'GRANDES-ROUSSES' 'HTE-MAURIE'\n",
      " 'HTE-TARENT' 'MONT-BLANC' 'VANOISE']\n",
      "    - Massif in test: ['BEAUFORTAIN' 'MAURIENNE' 'VERCORS']\n",
      "------------------ Fold: 5 ------------------\n",
      "    - Distribution class train: 0: 774 (50.00%), 1: 774 (50.00%)\n",
      "    - Distribution class test: 0: 198 (38.22%), 1: 320 (61.78%)\n",
      "    - Train size: 74.93%\n",
      "    - Massif in train: ['ARAVIS' 'BAUGES' 'BEAUFORTAIN' 'CHARTEUSE' 'GRANDES-ROUSSES'\n",
      " 'HTE-TARENT' 'MAURIENNE' 'VANOISE' 'VERCORS']\n",
      "    - Massif in test: ['BELLEDONNE' 'HTE-MAURIE' 'MONT-BLANC']\n",
      "------------------ Fold: 6 ------------------\n",
      "    - Distribution class train: 0: 911 (50.00%), 1: 911 (50.00%)\n",
      "    - Distribution class test: 0: 318 (63.47%), 1: 183 (36.53%)\n",
      "    - Train size: 78.43%\n",
      "    - Massif in train: ['ARAVIS' 'BEAUFORTAIN' 'BELLEDONNE' 'CHARTEUSE' 'MAURIENNE' 'MONT-BLANC'\n",
      " 'VANOISE']\n",
      "    - Massif in test: ['BAUGES' 'GRANDES-ROUSSES' 'HTE-MAURIE' 'HTE-TARENT' 'VERCORS']\n"
     ]
    }
   ],
   "source": [
    "results = combination_method(massives_count, train_size=0.8, proximity_value=1, shuffle=True, seed=100)\n",
    "results = balance_classes(results, targets, method=\"undersample\", seed=100)\n",
    "for kfold, (train_index, test_index) in enumerate(results):\n",
    "        print(f\"------------------ Fold: {kfold} ------------------\")\n",
    "        \n",
    "        train_unique_targets, train_target_counts = np.unique(targets[train_index], return_counts=True)\n",
    "        train_target_ratios = train_target_counts / train_target_counts.sum()\n",
    "        train_target_info = \", \".join(f\"{target}: {count} ({ratio:.2%})\" for target, count, ratio in zip(train_unique_targets, train_target_counts, train_target_ratios))\n",
    "        \n",
    "        test_unique_targets, test_target_counts = np.unique(targets[test_index], return_counts=True)\n",
    "        test_target_ratios = test_target_counts / test_target_counts.sum()\n",
    "        test_target_info = \", \".join(f\"{target}: {count} ({ratio:.2%})\" for target, count, ratio in zip(test_unique_targets, test_target_counts, test_target_ratios))\n",
    "        \n",
    "        print(f\"    - Distribution class train: {train_target_info}\")\n",
    "        print(f\"    - Distribution class test: {test_target_info}\")\n",
    "        print(f\"    - Train size: {len(train_index) / (len(train_index) + len(test_index)) * 100:.2f}%\")\n",
    "        print(f\"    - Massif in train: {np.unique(y['metadata'][train_index, 1])}\")\n",
    "        print(f\"    - Massif in test: {np.unique(y['metadata'][test_index, 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Fold: 0 ------------------\n",
      "    - Distribution class train: 0: 902 (50.00%), 1: 902 (50.00%)\n",
      "    - Distribution class test: 0: 328 (63.08%), 1: 192 (36.92%)\n",
      "    - Train size: 77.62%\n",
      "    - Massif in train: ['ARAVIS' 'BAUGES' 'BELLEDONNE' 'CHARTEUSE' 'GRANDES-ROUSSES' 'HTE-MAURIE'\n",
      " 'HTE-TARENT' 'MAURIENNE' 'MONT-BLANC']\n",
      "    - Massif in test: ['BEAUFORTAIN' 'VANOISE' 'VERCORS']\n",
      "------------------ Fold: 1 ------------------\n",
      "    - Distribution class train: 0: 757 (50.00%), 1: 757 (50.00%)\n",
      "    - Distribution class test: 0: 199 (37.13%), 1: 337 (62.87%)\n",
      "    - Train size: 73.85%\n",
      "    - Massif in train: ['ARAVIS' 'BAUGES' 'BEAUFORTAIN' 'CHARTEUSE' 'HTE-MAURIE' 'HTE-TARENT'\n",
      " 'MAURIENNE' 'VANOISE']\n",
      "    - Massif in test: ['BELLEDONNE' 'GRANDES-ROUSSES' 'MONT-BLANC' 'VERCORS']\n",
      "------------------ Fold: 2 ------------------\n",
      "    - Distribution class train: 0: 883 (50.00%), 1: 883 (50.00%)\n",
      "    - Distribution class test: 0: 295 (58.30%), 1: 211 (41.70%)\n",
      "    - Train size: 77.73%\n",
      "    - Massif in train: ['ARAVIS' 'BAUGES' 'BEAUFORTAIN' 'BELLEDONNE' 'HTE-MAURIE' 'HTE-TARENT'\n",
      " 'MAURIENNE' 'MONT-BLANC' 'VANOISE']\n",
      "    - Massif in test: ['CHARTEUSE' 'GRANDES-ROUSSES' 'VERCORS']\n",
      "------------------ Fold: 3 ------------------\n",
      "    - Distribution class train: 0: 892 (50.00%), 1: 892 (50.00%)\n",
      "    - Distribution class test: 0: 316 (61.00%), 1: 202 (39.00%)\n",
      "    - Train size: 77.50%\n",
      "    - Massif in train: ['ARAVIS' 'BAUGES' 'BEAUFORTAIN' 'BELLEDONNE' 'HTE-MAURIE' 'MAURIENNE'\n",
      " 'MONT-BLANC' 'VANOISE' 'VERCORS']\n",
      "    - Massif in test: ['CHARTEUSE' 'GRANDES-ROUSSES' 'HTE-TARENT']\n",
      "------------------ Fold: 4 ------------------\n",
      "    - Distribution class train: 0: 921 (50.00%), 1: 921 (50.00%)\n",
      "    - Distribution class test: 0: 366 (67.90%), 1: 173 (32.10%)\n",
      "    - Train size: 77.36%\n",
      "    - Massif in train: ['ARAVIS' 'BAUGES' 'BELLEDONNE' 'CHARTEUSE' 'GRANDES-ROUSSES' 'HTE-MAURIE'\n",
      " 'HTE-TARENT' 'MONT-BLANC' 'VANOISE']\n",
      "    - Massif in test: ['BEAUFORTAIN' 'MAURIENNE' 'VERCORS']\n",
      "------------------ Fold: 5 ------------------\n",
      "    - Distribution class train: 0: 774 (50.00%), 1: 774 (50.00%)\n",
      "    - Distribution class test: 0: 198 (38.22%), 1: 320 (61.78%)\n",
      "    - Train size: 74.93%\n",
      "    - Massif in train: ['ARAVIS' 'BAUGES' 'BEAUFORTAIN' 'CHARTEUSE' 'GRANDES-ROUSSES'\n",
      " 'HTE-TARENT' 'MAURIENNE' 'VANOISE' 'VERCORS']\n",
      "    - Massif in test: ['BELLEDONNE' 'HTE-MAURIE' 'MONT-BLANC']\n",
      "------------------ Fold: 6 ------------------\n",
      "    - Distribution class train: 0: 911 (50.00%), 1: 911 (50.00%)\n",
      "    - Distribution class test: 0: 318 (63.47%), 1: 183 (36.53%)\n",
      "    - Train size: 78.43%\n",
      "    - Massif in train: ['ARAVIS' 'BEAUFORTAIN' 'BELLEDONNE' 'CHARTEUSE' 'MAURIENNE' 'MONT-BLANC'\n",
      " 'VANOISE']\n",
      "    - Massif in test: ['BAUGES' 'GRANDES-ROUSSES' 'HTE-MAURIE' 'HTE-TARENT' 'VERCORS']\n"
     ]
    }
   ],
   "source": [
    "for kfold, (train_index, test_index) in enumerate(results):\n",
    "        print(f\"------------------ Fold: {kfold} ------------------\")\n",
    "        \n",
    "        train_unique_targets, train_target_counts = np.unique(targets[train_index], return_counts=True)\n",
    "        train_target_ratios = train_target_counts / train_target_counts.sum()\n",
    "        train_target_info = \", \".join(f\"{target}: {count} ({ratio:.2%})\" for target, count, ratio in zip(train_unique_targets, train_target_counts, train_target_ratios))\n",
    "        \n",
    "        test_unique_targets, test_target_counts = np.unique(targets[test_index], return_counts=True)\n",
    "        test_target_ratios = test_target_counts / test_target_counts.sum()\n",
    "        test_target_info = \", \".join(f\"{target}: {count} ({ratio:.2%})\" for target, count, ratio in zip(test_unique_targets, test_target_counts, test_target_ratios))\n",
    "        \n",
    "        print(f\"    - Distribution class train: {train_target_info}\")\n",
    "        print(f\"    - Distribution class test: {test_target_info}\")\n",
    "        print(f\"    - Train size: {len(train_index) / (len(train_index) + len(test_index)) * 100:.2f}%\")\n",
    "        print(f\"    - Massif in train: {np.unique(y['metadata'][train_index, 1])}\")\n",
    "        print(f\"    - Massif in test: {np.unique(y['metadata'][test_index, 1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------ Fold: 0 ------------------\n",
      "    - Distribution class train: 0: 934 (50.00%), 1: 934 (50.00%)\n",
      "    - Distribution class test: 0: 371 (69.87%), 1: 160 (30.13%)\n",
      "    - Train size: 77.87%\n",
      "    - Massif in train: ['ARAVIS' 'BAUGES' 'BELLEDONNE' 'CHARTEUSE' 'GRANDES-ROUSSES' 'HTE-TARENT'\n",
      " 'MONT-BLANC' 'VANOISE' 'VERCORS']\n",
      "    - Massif in test: ['BEAUFORTAIN' 'HTE-MAURIE' 'MAURIENNE']\n",
      "------------------ Fold: 1 ------------------\n",
      "    - Distribution class train: 0: 774 (50.00%), 1: 774 (50.00%)\n",
      "    - Distribution class test: 0: 198 (38.22%), 1: 320 (61.78%)\n",
      "    - Train size: 74.93%\n",
      "    - Massif in train: ['ARAVIS' 'BAUGES' 'BEAUFORTAIN' 'CHARTEUSE' 'GRANDES-ROUSSES'\n",
      " 'HTE-TARENT' 'MAURIENNE' 'VANOISE' 'VERCORS']\n",
      "    - Massif in test: ['BELLEDONNE' 'HTE-MAURIE' 'MONT-BLANC']\n",
      "------------------ Fold: 2 ------------------\n",
      "    - Distribution class train: 0: 774 (50.00%), 1: 774 (50.00%)\n",
      "    - Distribution class test: 0: 195 (37.86%), 1: 320 (62.14%)\n",
      "    - Train size: 75.04%\n",
      "    - Massif in train: ['ARAVIS' 'BAUGES' 'BEAUFORTAIN' 'CHARTEUSE' 'HTE-MAURIE' 'HTE-TARENT'\n",
      " 'MAURIENNE' 'VANOISE' 'VERCORS']\n",
      "    - Massif in test: ['BELLEDONNE' 'GRANDES-ROUSSES' 'MONT-BLANC']\n",
      "------------------ Fold: 3 ------------------\n",
      "    - Distribution class train: 0: 911 (50.00%), 1: 911 (50.00%)\n",
      "    - Distribution class test: 0: 339 (64.94%), 1: 183 (35.06%)\n",
      "    - Train size: 77.73%\n",
      "    - Massif in train: ['ARAVIS' 'BAUGES' 'BELLEDONNE' 'CHARTEUSE' 'HTE-TARENT' 'MAURIENNE'\n",
      " 'MONT-BLANC' 'VERCORS']\n",
      "    - Massif in test: ['BEAUFORTAIN' 'GRANDES-ROUSSES' 'HTE-MAURIE' 'VANOISE']\n",
      "------------------ Fold: 4 ------------------\n",
      "    - Distribution class train: 0: 898 (50.00%), 1: 898 (50.00%)\n",
      "    - Distribution class test: 0: 334 (63.02%), 1: 196 (36.98%)\n",
      "    - Train size: 77.21%\n",
      "    - Massif in train: ['ARAVIS' 'BAUGES' 'BELLEDONNE' 'CHARTEUSE' 'HTE-MAURIE' 'HTE-TARENT'\n",
      " 'MAURIENNE' 'MONT-BLANC']\n",
      "    - Massif in test: ['BEAUFORTAIN' 'GRANDES-ROUSSES' 'VANOISE' 'VERCORS']\n",
      "------------------ Fold: 5 ------------------\n",
      "    - Distribution class train: 0: 879 (50.00%), 1: 879 (50.00%)\n",
      "    - Distribution class test: 0: 314 (59.36%), 1: 215 (40.64%)\n",
      "    - Train size: 76.87%\n",
      "    - Massif in train: ['ARAVIS' 'BAUGES' 'BEAUFORTAIN' 'BELLEDONNE' 'GRANDES-ROUSSES'\n",
      " 'HTE-MAURIE' 'MAURIENNE' 'MONT-BLANC' 'VANOISE']\n",
      "    - Massif in test: ['CHARTEUSE' 'HTE-TARENT' 'VERCORS']\n",
      "------------------ Fold: 6 ------------------\n",
      "    - Distribution class train: 0: 915 (50.00%), 1: 915 (50.00%)\n",
      "    - Distribution class test: 0: 312 (63.54%), 1: 179 (36.46%)\n",
      "    - Train size: 78.85%\n",
      "    - Massif in train: ['ARAVIS' 'BEAUFORTAIN' 'BELLEDONNE' 'CHARTEUSE' 'GRANDES-ROUSSES'\n",
      " 'MAURIENNE' 'MONT-BLANC' 'VANOISE']\n",
      "    - Massif in test: ['BAUGES' 'HTE-MAURIE' 'HTE-TARENT' 'VERCORS']\n"
     ]
    }
   ],
   "source": [
    "for kfold, (train_index, test_index) in enumerate(results):\n",
    "        print(f\"------------------ Fold: {kfold} ------------------\")\n",
    "        \n",
    "        train_unique_targets, train_target_counts = np.unique(targets[train_index], return_counts=True)\n",
    "        train_target_ratios = train_target_counts / train_target_counts.sum()\n",
    "        train_target_info = \", \".join(f\"{target}: {count} ({ratio:.2%})\" for target, count, ratio in zip(train_unique_targets, train_target_counts, train_target_ratios))\n",
    "        \n",
    "        test_unique_targets, test_target_counts = np.unique(targets[test_index], return_counts=True)\n",
    "        test_target_ratios = test_target_counts / test_target_counts.sum()\n",
    "        test_target_info = \", \".join(f\"{target}: {count} ({ratio:.2%})\" for target, count, ratio in zip(test_unique_targets, test_target_counts, test_target_ratios))\n",
    "        \n",
    "        print(f\"    - Distribution class train: {train_target_info}\")\n",
    "        print(f\"    - Distribution class test: {test_target_info}\")\n",
    "        print(f\"    - Train size: {len(train_index) / (len(train_index) + len(test_index)) * 100:.2f}%\")\n",
    "        print(f\"    - Massif in train: {np.unique(y['metadata'][train_index, 1])}\")\n",
    "        print(f\"    - Massif in test: {np.unique(y['metadata'][test_index, 1])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
